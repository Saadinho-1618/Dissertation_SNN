{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded VOC2007 sample test data: 100 images.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from akida_models import fetch_file\n",
    "\n",
    "# Download TFrecords test set from Brainchip data server\n",
    "data_path = fetch_file(\n",
    "    fname=\"voc_test_20_classes.tfrecord\",\n",
    "    origin=\"https://data.brainchip.com/dataset-mirror/voc/test_20_classes.tfrecord\",\n",
    "    cache_subdir='datasets/voc',\n",
    "    extract=True)\n",
    "\n",
    "\n",
    "\n",
    "# Helper function to load and parse the Tfrecord file.\n",
    "def load_tf_dataset(tf_record_file_path):\n",
    "    tfrecord_files = [tf_record_file_path]\n",
    "\n",
    "    # Feature description for parsing the TFRecord\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'objects/bbox': tf.io.VarLenFeature(tf.float32),\n",
    "        'objects/label': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "\n",
    "    def _count_tfrecord_examples(dataset):\n",
    "        return len(list(dataset.as_numpy_iterator()))\n",
    "\n",
    "    def _parse_tfrecord_fn(example_proto):\n",
    "        example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "        # Decode the image from bytes\n",
    "        example['image'] = tf.io.decode_jpeg(example['image'], channels=3)\n",
    "\n",
    "        # Convert the VarLenFeature to a dense tensor\n",
    "        example['objects/label'] = tf.sparse.to_dense(example['objects/label'], default_value=0)\n",
    "\n",
    "        example['objects/bbox'] = tf.sparse.to_dense(example['objects/bbox'])\n",
    "        # Boxes were flattenned that's why we need to reshape them\n",
    "        example['objects/bbox'] = tf.reshape(example['objects/bbox'],\n",
    "                                             (tf.shape(example['objects/label'])[0], 4))\n",
    "        # Create a new dictionary structure\n",
    "        objects = {\n",
    "            'label': example['objects/label'],\n",
    "            'bbox': example['objects/bbox'],\n",
    "        }\n",
    "\n",
    "        # Remove unnecessary keys\n",
    "        example.pop('objects/label')\n",
    "        example.pop('objects/bbox')\n",
    "\n",
    "        # Add 'objects' key to the main dictionary\n",
    "        example['objects'] = objects\n",
    "\n",
    "        return example\n",
    "\n",
    "    # Create a TFRecordDataset\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    len_dataset = _count_tfrecord_examples(dataset)\n",
    "    #len_dataset = sum(1 for _ in val_dataset)\n",
    "    parsed_dataset = dataset.map(_parse_tfrecord_fn)\n",
    "\n",
    "    return parsed_dataset, len_dataset\n",
    "\n",
    "\n",
    "labels = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "          'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n",
    "          'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\n",
    "          'train', 'tvmonitor']\n",
    "\n",
    "val_dataset, len_val_dataset = load_tf_dataset(data_path)\n",
    "print(f\"Loaded VOC2007 sample test data: {len_val_dataset} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average IOU for 5 anchors: 0.70\n",
      "Anchors:  [[1.12454, 1.84751], [1.93628, 2.82636], [3.16509, 3.61125], [4.55423, 5.11091], [5.43139, 5.86134]]\n"
     ]
    }
   ],
   "source": [
    "from akida_models.detection.generate_anchors import generate_anchors\n",
    "\n",
    "num_anchors = 5\n",
    "grid_size = (7, 7)\n",
    "anchors = generate_anchors(val_dataset, num_anchors, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (QuantizedRescali  (None, 224, 224, 3)      0         \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " conv_0 (QuantizedConv2D)    (None, 112, 112, 16)      448       \n",
      "                                                                 \n",
      " conv_0/relu (QuantizedReLU)  (None, 112, 112, 16)     32        \n",
      "                                                                 \n",
      " conv_1 (QuantizedConv2D)    (None, 112, 112, 32)      4640      \n",
      "                                                                 \n",
      " conv_1/relu (QuantizedReLU)  (None, 112, 112, 32)     64        \n",
      "                                                                 \n",
      " conv_2 (QuantizedConv2D)    (None, 56, 56, 64)        18496     \n",
      "                                                                 \n",
      " conv_2/relu (QuantizedReLU)  (None, 56, 56, 64)       128       \n",
      "                                                                 \n",
      " conv_3 (QuantizedConv2D)    (None, 56, 56, 64)        36928     \n",
      "                                                                 \n",
      " conv_3/relu (QuantizedReLU)  (None, 56, 56, 64)       128       \n",
      "                                                                 \n",
      " dw_separable_4 (QuantizedDe  (None, 28, 28, 64)       704       \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_4 (QuantizedCo  (None, 28, 28, 128)      8320      \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_4/relu (Quanti  (None, 28, 28, 128)      256       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_5 (QuantizedDe  (None, 28, 28, 128)      1408      \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_5 (QuantizedCo  (None, 28, 28, 128)      16512     \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_5/relu (Quanti  (None, 28, 28, 128)      256       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_6 (QuantizedDe  (None, 14, 14, 128)      1408      \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_6 (QuantizedCo  (None, 14, 14, 256)      33024     \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_6/relu (Quanti  (None, 14, 14, 256)      512       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_7 (QuantizedDe  (None, 14, 14, 256)      2816      \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_7 (QuantizedCo  (None, 14, 14, 256)      65792     \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_7/relu (Quanti  (None, 14, 14, 256)      512       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_8 (QuantizedDe  (None, 14, 14, 256)      2816      \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_8 (QuantizedCo  (None, 14, 14, 256)      65792     \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_8/relu (Quanti  (None, 14, 14, 256)      512       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_9 (QuantizedDe  (None, 14, 14, 256)      2816      \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_9 (QuantizedCo  (None, 14, 14, 256)      65792     \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_9/relu (Quanti  (None, 14, 14, 256)      512       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_10 (QuantizedD  (None, 14, 14, 256)      2816      \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_10 (QuantizedC  (None, 14, 14, 256)      65792     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_10/relu (Quant  (None, 14, 14, 256)      512       \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_11 (QuantizedD  (None, 14, 14, 256)      2816      \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_11 (QuantizedC  (None, 14, 14, 256)      65792     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_11/relu (Quant  (None, 14, 14, 256)      512       \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_12 (QuantizedD  (None, 7, 7, 256)        2816      \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_12 (QuantizedC  (None, 7, 7, 512)        131584    \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_12/relu (Quant  (None, 7, 7, 512)        1024      \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_13 (QuantizedD  (None, 7, 7, 512)        5632      \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_13 (QuantizedC  (None, 7, 7, 512)        262656    \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_13/relu (Quant  (None, 7, 7, 512)        1024      \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_1conv (QuantizedDepthwis  (None, 7, 7, 512)        5632      \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " pw_1conv (QuantizedConv2D)  (None, 7, 7, 1024)        525312    \n",
      "                                                                 \n",
      " pw_1conv/relu (QuantizedReL  (None, 7, 7, 1024)       2048      \n",
      " U)                                                              \n",
      "                                                                 \n",
      " dw_2conv (QuantizedDepthwis  (None, 7, 7, 1024)       11264     \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " pw_2conv (QuantizedConv2D)  (None, 7, 7, 1024)        1049600   \n",
      "                                                                 \n",
      " pw_2conv/relu (QuantizedReL  (None, 7, 7, 1024)       2048      \n",
      " U)                                                              \n",
      "                                                                 \n",
      " dw_3conv (QuantizedDepthwis  (None, 7, 7, 1024)       11264     \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " pw_3conv (QuantizedConv2D)  (None, 7, 7, 1024)        1049600   \n",
      "                                                                 \n",
      " pw_3conv/relu (QuantizedReL  (None, 7, 7, 1024)       2048      \n",
      " U)                                                              \n",
      "                                                                 \n",
      " dw_detection_layer (Quantiz  (None, 7, 7, 1024)       11264     \n",
      " edDepthwiseConv2D)                                              \n",
      "                                                                 \n",
      " voc_classifier (QuantizedCo  (None, 7, 7, 125)        128125    \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " dequantizer (Dequantizer)   (None, 7, 7, 125)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,671,805\n",
      "Trainable params: 3,647,773\n",
      "Non-trainable params: 24,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "from akida_models import yolo_voc_pretrained\n",
    "from akida_models.detection.map_evaluation import MapEvaluation\n",
    "\n",
    "# Load the pretrained model along with anchors\n",
    "model_keras, anchors = yolo_voc_pretrained()\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (QuantizedRescali  (None, 224, 224, 3)      0         \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " conv_0 (QuantizedConv2D)    (None, 112, 112, 16)      448       \n",
      "                                                                 \n",
      " conv_0/relu (QuantizedReLU)  (None, 112, 112, 16)     32        \n",
      "                                                                 \n",
      " conv_1 (QuantizedConv2D)    (None, 112, 112, 32)      4640      \n",
      "                                                                 \n",
      " conv_1/relu (QuantizedReLU)  (None, 112, 112, 32)     64        \n",
      "                                                                 \n",
      " conv_2 (QuantizedConv2D)    (None, 56, 56, 64)        18496     \n",
      "                                                                 \n",
      " conv_2/relu (QuantizedReLU)  (None, 56, 56, 64)       128       \n",
      "                                                                 \n",
      " conv_3 (QuantizedConv2D)    (None, 56, 56, 64)        36928     \n",
      "                                                                 \n",
      " conv_3/relu (QuantizedReLU)  (None, 56, 56, 64)       128       \n",
      "                                                                 \n",
      " dw_separable_4 (QuantizedDe  (None, 28, 28, 64)       704       \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_4 (QuantizedCo  (None, 28, 28, 128)      8320      \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_4/relu (Quanti  (None, 28, 28, 128)      256       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_5 (QuantizedDe  (None, 28, 28, 128)      1408      \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_5 (QuantizedCo  (None, 28, 28, 128)      16512     \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_5/relu (Quanti  (None, 28, 28, 128)      256       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_6 (QuantizedDe  (None, 14, 14, 128)      1408      \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_6 (QuantizedCo  (None, 14, 14, 256)      33024     \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_6/relu (Quanti  (None, 14, 14, 256)      512       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_7 (QuantizedDe  (None, 14, 14, 256)      2816      \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_7 (QuantizedCo  (None, 14, 14, 256)      65792     \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_7/relu (Quanti  (None, 14, 14, 256)      512       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_8 (QuantizedDe  (None, 14, 14, 256)      2816      \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_8 (QuantizedCo  (None, 14, 14, 256)      65792     \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_8/relu (Quanti  (None, 14, 14, 256)      512       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_9 (QuantizedDe  (None, 14, 14, 256)      2816      \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_9 (QuantizedCo  (None, 14, 14, 256)      65792     \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_9/relu (Quanti  (None, 14, 14, 256)      512       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_10 (QuantizedD  (None, 14, 14, 256)      2816      \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_10 (QuantizedC  (None, 14, 14, 256)      65792     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_10/relu (Quant  (None, 14, 14, 256)      512       \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_11 (QuantizedD  (None, 14, 14, 256)      2816      \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_11 (QuantizedC  (None, 14, 14, 256)      65792     \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_11/relu (Quant  (None, 14, 14, 256)      512       \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_12 (QuantizedD  (None, 7, 7, 256)        2816      \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_12 (QuantizedC  (None, 7, 7, 512)        131584    \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_12/relu (Quant  (None, 7, 7, 512)        1024      \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_separable_13 (QuantizedD  (None, 7, 7, 512)        5632      \n",
      " epthwiseConv2D)                                                 \n",
      "                                                                 \n",
      " pw_separable_13 (QuantizedC  (None, 7, 7, 512)        262656    \n",
      " onv2D)                                                          \n",
      "                                                                 \n",
      " pw_separable_13/relu (Quant  (None, 7, 7, 512)        1024      \n",
      " izedReLU)                                                       \n",
      "                                                                 \n",
      " dw_1conv (QuantizedDepthwis  (None, 7, 7, 512)        5632      \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " pw_1conv (QuantizedConv2D)  (None, 7, 7, 1024)        525312    \n",
      "                                                                 \n",
      " pw_1conv/relu (QuantizedReL  (None, 7, 7, 1024)       2048      \n",
      " U)                                                              \n",
      "                                                                 \n",
      " dw_2conv (QuantizedDepthwis  (None, 7, 7, 1024)       11264     \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " pw_2conv (QuantizedConv2D)  (None, 7, 7, 1024)        1049600   \n",
      "                                                                 \n",
      " pw_2conv/relu (QuantizedReL  (None, 7, 7, 1024)       2048      \n",
      " U)                                                              \n",
      "                                                                 \n",
      " dw_3conv (QuantizedDepthwis  (None, 7, 7, 1024)       11264     \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " pw_3conv (QuantizedConv2D)  (None, 7, 7, 1024)        1049600   \n",
      "                                                                 \n",
      " pw_3conv/relu (QuantizedReL  (None, 7, 7, 1024)       2048      \n",
      " U)                                                              \n",
      "                                                                 \n",
      " dw_detection_layer (Quantiz  (None, 7, 7, 1024)       11264     \n",
      " edDepthwiseConv2D)                                              \n",
      "                                                                 \n",
      " voc_classifier (QuantizedCo  (None, 7, 7, 125)        128125    \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " dequantizer (Dequantizer)   (None, 7, 7, 125)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,671,805\n",
      "Trainable params: 3,647,773\n",
      "Non-trainable params: 24,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define QuantizationParams with specific values just for the sake of understanding the JSON\n",
    "# configuration that follows.\n",
    "\n",
    "import quantizeml\n",
    "import json\n",
    "from quantizeml.models import quantize, QuantizationParams,dump_config\n",
    "qparams = QuantizationParams(input_weight_bits=8, weight_bits=8, activation_bits=8, output_bits=8,\n",
    "                             per_tensor_activations=True, buffer_bits=24)\n",
    "\n",
    "# Quantize the model\n",
    "quantized_model = quantize(model_keras, qparams=qparams)\n",
    "quantized_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define QuantizationParams with specific values just for the sake of understanding the JSON\n",
    "# configuration that follows.\n",
    "\n",
    "import quantizeml\n",
    "import json\n",
    "from quantizeml.models import quantize, QuantizationParams,dump_config\n",
    "qparams = QuantizationParams(input_weight_bits=8, weight_bits=4, activation_bits=4,\n",
    "                             per_tensor_activations=True, buffer_bits=24)\n",
    "\n",
    "# Quantize the model\n",
    "quantized_model = quantize(model_keras, qparams=qparams)\n",
    "quantized_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define QuantizationParams with specific values just for the sake of understanding the JSON\n",
    "# configuration that follows.\n",
    "\n",
    "import quantizeml\n",
    "import json\n",
    "from quantizeml.models import quantize, QuantizationParams,dump_config\n",
    "qparams = QuantizationParams(input_weight_bits=8, weight_bits=2, activation_bits=2, output_bits=2,\n",
    "                             per_tensor_activations=True, buffer_bits=24)\n",
    "\n",
    "# Quantize the model\n",
    "quantized_model = quantize(model_keras, qparams=qparams)\n",
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aeroplane 0.7300\n",
      "bicycle 0.4417\n",
      "bird 0.4833\n",
      "boat 0.3070\n",
      "bottle 0.2627\n",
      "bus 0.7147\n",
      "car 0.6889\n",
      "cat 0.7670\n",
      "chair 0.2726\n",
      "cow 0.3700\n",
      "diningtable 0.4711\n",
      "dog 0.5736\n",
      "horse 0.6147\n",
      "motorbike 0.5083\n",
      "person 0.4021\n",
      "pottedplant 0.1094\n",
      "sheep 0.2976\n",
      "sofa 0.6283\n",
      "train 0.6042\n",
      "tvmonitor 0.5643\n",
      "mAP 50: 0.8409\n",
      "mAP 75: 0.5086\n",
      "mAP: 0.4906\n",
      "Keras inference on 100 images took 18.83 s.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from akida_models.detection.map_evaluation import MapEvaluation\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "# Define the final reshape and build the model\n",
    "classes = len(labels)\n",
    "model_keras = quantized_model\n",
    "output = Reshape((grid_size[1], grid_size[0], num_anchors, 4 + 1 + classes),\n",
    "                 name=\"YOLO_output\")(model_keras.output)\n",
    "model_keras = Model(model_keras.input, output)\n",
    "\n",
    "# Create the mAP evaluator object\n",
    "map_evaluator = MapEvaluation(model_keras, val_dataset,\n",
    "                              len_val_dataset, labels, anchors)\n",
    "\n",
    "# Compute the scores for all validation images\n",
    "start = timer()\n",
    "\n",
    "map_dict, average_precisions = map_evaluator.evaluate_map()\n",
    "mAP = sum(map_dict.values()) / len(map_dict)\n",
    "end = timer()\n",
    "\n",
    "for label, average_precision in average_precisions.items():\n",
    "    print(labels[label], '{:.4f}'.format(average_precision))\n",
    "print('mAP 50: {:.4f}'.format(map_dict[0.5]))\n",
    "print('mAP 75: {:.4f}'.format(map_dict[0.75]))\n",
    "print('mAP: {:.4f}'.format(mAP))\n",
    "print(f'Keras inference on {len_val_dataset} images took {end-start:.2f} s.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild a model without the last layer\n",
    "compatible_model = Model(model_keras.input, model_keras.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn2snn import convert\n",
    "\n",
    "model_akida = convert(compatible_model)\n",
    "model_akida.summary()\n",
    "#\n",
    "#compatible_model_no_remove = Model(quantized_model.input, quantized_model.layers[0].output)\n",
    "#compatible_model_1_remove = Model(quantized_model.input, quantized_model.layers[-1].output)\n",
    "#compatible_model_2_remove = Model(quantized_model.input, quantized_model.layers[-2].output)\n",
    "#\n",
    "#compatible_model_no_remove.summary()\n",
    "#compatible_model_1_remove.summary()\n",
    "#compatible_model_2_remove.summary()\n",
    "#\n",
    "##quantized_model.summary()\n",
    "#model_akida = convert(compatible_model_1_remove)\n",
    "#model_akida.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "\n",
    "    def start(self):\n",
    "        self.start_time = time.perf_counter()\n",
    "\n",
    "    def stop(self):\n",
    "        self.end_time = time.perf_counter()\n",
    "        return self.end_time - self.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in val_dataset.take(1):\n",
    "    first_image = element['image']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import time\n",
    "\n",
    "from akida_models.detection.processing import preprocess_image, decode_output\n",
    "\n",
    "# Shuffle the data to take a random test image\n",
    "#val_dataset = val_dataset.shuffle(buffer_size=1)\n",
    "\n",
    "\n",
    "input_shape = model_akida.layers[0].input_dims\n",
    "\n",
    "# Load the image\n",
    "# raw_image = next(iter(val_dataset))['image']\n",
    "raw_image=first_image\n",
    "\n",
    "# Keep the original image size for later bounding boxes rescaling\n",
    "raw_height, raw_width, _ = raw_image.shape\n",
    "\n",
    "# Pre-process the image\n",
    "image = preprocess_image(raw_image, input_shape)\n",
    "input_image = image[np.newaxis, :].astype(np.uint8)\n",
    "timer = timer\n",
    "# Call evaluate on the image\n",
    "timer = Timer()\n",
    "timer.start()\n",
    "pots = model_akida.predict(input_image)[0]\n",
    "prediction_time = timer.stop()\n",
    "print(f\"Prediction took {prediction_time:.4f} seconds\")\n",
    "# Reshape the potentials to prepare for decoding\n",
    "h, w, c = pots.shape\n",
    "pots = pots.reshape((h, w, len(anchors), 4 + 1 + len(labels)))\n",
    "\n",
    "# Decode potentials into bounding boxes\n",
    "raw_boxes = decode_output(pots, anchors, len(labels))\n",
    "\n",
    "# Rescale boxes to the original image size\n",
    "pred_boxes = np.array([[\n",
    "    box.x1 * raw_width, box.y1 * raw_height, box.x2 * raw_width,\n",
    "    box.y2 * raw_height,\n",
    "    box.get_label(),\n",
    "    box.get_score()\n",
    "] for box in raw_boxes])\n",
    "\n",
    "fig = plt.figure(num='VOC detection by Akida')\n",
    "ax = fig.subplots(1)\n",
    "img_plot = ax.imshow(np.zeros(raw_image.shape, dtype=np.uint8))\n",
    "img_plot.set_data(raw_image)\n",
    "\n",
    "for box in pred_boxes:\n",
    "    rect = patches.Rectangle((box[0], box[1]),\n",
    "                             box[2] - box[0],\n",
    "                             box[3] - box[1],\n",
    "                             linewidth=1,\n",
    "                             edgecolor='r',\n",
    "                             facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    class_score = ax.text(box[0],\n",
    "                          box[1] - 5,\n",
    "                          f\"{labels[int(box[4])]} - {box[5]:.2f}\",\n",
    "                          color='red')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Labels for the PASCAL VOC dataset\n",
    "labels = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "          'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n",
    "          'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\n",
    "          'train', 'tvmonitor']\n",
    "\n",
    "# Initialize video capture from the inbuilt camera\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Define anchors (you might need to adjust these based on your model)\n",
    "#anchors = np.array([[1.08, 1.19], [3.42, 4.41], [6.63, 11.38], [9.42, 5.11], [16.62, 10.52]])\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Keep the original image size for later bounding boxes rescaling\n",
    "    raw_height, raw_width, _ = frame.shape\n",
    "\n",
    "    # Pre-process the image\n",
    "    input_shape = model_akida.input_shape[1:3]  # Correctly access input shape\n",
    "    image = preprocess_image(frame, input_shape)\n",
    "    input_image = image[np.newaxis, :].astype(np.uint8)\n",
    "\n",
    "    # Call evaluate on the image\n",
    "    timer = Timer()\n",
    "    timer.start()\n",
    "    pots = model_akida.predict(input_image)[0]\n",
    "    prediction_time = timer.stop()\n",
    "    print(f\"Prediction took {prediction_time:.4f} seconds\")\n",
    "    \n",
    "    # Reshape the potentials to prepare for decoding\n",
    "    h, w, c = pots.shape\n",
    "    pots = pots.reshape((h, w, len(anchors), 4 + 1 + len(labels)))\n",
    "\n",
    "    # Decode potentials into bounding boxes\n",
    "    raw_boxes = decode_output(pots, anchors, len(labels))\n",
    "\n",
    "    # Rescale boxes to the original image size\n",
    "    pred_boxes = np.array([[\n",
    "        box.x1 * raw_width, box.y1 * raw_height, box.x2 * raw_width,\n",
    "        box.y2 * raw_height,\n",
    "        box.get_label(),\n",
    "        box.get_score()\n",
    "    ] for box in raw_boxes])\n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    for box in pred_boxes:\n",
    "        cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
    "        label = f\"{labels[int(box[4])]} - {box[5]:.2f}\"\n",
    "        cv2.putText(frame, label, (int(box[0]), int(box[1]) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('YOLO Video Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissertation_Environment2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
