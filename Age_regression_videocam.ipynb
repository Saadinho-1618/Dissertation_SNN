{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from akida_models.utk_face.preprocessing import load_data\n",
    "\n",
    "# Load the dataset\n",
    "x_train, y_train, x_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Akida inference, use uint8 raw data\n",
    "x_test_akida = x_test.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"vgg_utk_face\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " conv_0 (Conv2D)             (None, 30, 30, 32)        864       \n",
      "                                                                 \n",
      " conv_0/BN (BatchNormalizati  (None, 30, 30, 32)       128       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_0/relu (ReLU)          (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " conv_1 (Conv2D)             (None, 30, 30, 32)        9216      \n",
      "                                                                 \n",
      " conv_1/maxpool (MaxPooling2  (None, 15, 15, 32)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_1/BN (BatchNormalizati  (None, 15, 15, 32)       128       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_1/relu (ReLU)          (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 15, 15, 64)        18432     \n",
      "                                                                 \n",
      " conv_2/BN (BatchNormalizati  (None, 15, 15, 64)       256       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_2/relu (ReLU)          (None, 15, 15, 64)        0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 15, 15, 64)        36864     \n",
      "                                                                 \n",
      " conv_3/maxpool (MaxPooling2  (None, 8, 8, 64)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_3/BN (BatchNormalizati  (None, 8, 8, 64)         256       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_3/relu (ReLU)          (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " conv_4 (Conv2D)             (None, 8, 8, 84)          48384     \n",
      "                                                                 \n",
      " conv_4/BN (BatchNormalizati  (None, 8, 8, 84)         336       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_4/relu (ReLU)          (None, 8, 8, 84)          0         \n",
      "                                                                 \n",
      " conv_4/global_avg (GlobalAv  (None, 84)               0         \n",
      " eragePooling2D)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                5376      \n",
      "                                                                 \n",
      " dense_1/BN (BatchNormalizat  (None, 64)               256       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_1/relu (ReLU)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,561\n",
      "Trainable params: 119,881\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from akida_models import fetch_file\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Retrieve the model file from the BrainChip data server\n",
    "model_file = fetch_file(fname=\"vgg_utk_face.h5\",\n",
    "                        origin=\"https://data.brainchip.com/models/AkidaV2/vgg/vgg_utk_face.h5\",\n",
    "                        cache_subdir='models')\n",
    "\n",
    "# Load the native Keras pre-trained model\n",
    "model_keras = load_model(model_file)\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras MAE: 6.0806\n"
     ]
    }
   ],
   "source": [
    "# Compile the native Keras model (required to evaluate the MAE)\n",
    "model_keras.compile(optimizer='Adam', loss='mae')\n",
    "\n",
    "# Check Keras model performance\n",
    "mae_keras = model_keras.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Keras MAE: {0:.4f}\".format(mae_keras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 2s 2ms/step\n",
      "Model: \"vgg_utk_face\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " rescaling (QuantizedRescali  (None, 32, 32, 3)        0         \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " conv_0 (QuantizedConv2D)    (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " conv_0/relu (QuantizedReLU)  (None, 30, 30, 32)       2         \n",
      "                                                                 \n",
      " conv_1 (QuantizedConv2D)    (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " conv_1/maxpool (QuantizedMa  (None, 15, 15, 32)       0         \n",
      " xPool2D)                                                        \n",
      "                                                                 \n",
      " conv_1/relu (QuantizedReLU)  (None, 15, 15, 32)       2         \n",
      "                                                                 \n",
      " dropout_3 (QuantizedDropout  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_2 (QuantizedConv2D)    (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " conv_2/relu (QuantizedReLU)  (None, 15, 15, 64)       2         \n",
      "                                                                 \n",
      " conv_3 (QuantizedConv2D)    (None, 15, 15, 64)        36928     \n",
      "                                                                 \n",
      " conv_3/maxpool (QuantizedMa  (None, 8, 8, 64)         0         \n",
      " xPool2D)                                                        \n",
      "                                                                 \n",
      " conv_3/relu (QuantizedReLU)  (None, 8, 8, 64)         2         \n",
      "                                                                 \n",
      " dropout_4 (QuantizedDropout  (None, 8, 8, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_4 (QuantizedConv2D)    (None, 8, 8, 84)          48468     \n",
      "                                                                 \n",
      " conv_4/relu (QuantizedReLU)  (None, 8, 8, 84)         0         \n",
      "                                                                 \n",
      " conv_4/global_avg (Quantize  (None, 84)               2         \n",
      " dGlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_5 (QuantizedDropout  (None, 84)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (QuantizedDense)    (None, 64)                5440      \n",
      "                                                                 \n",
      " dense_1/relu (QuantizedReLU  (None, 64)               2         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_2 (QuantizedDense)    (None, 1)                 65        \n",
      "                                                                 \n",
      " dequantizer_1 (Dequantizer)  (None, 1)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,553\n",
      "Trainable params: 119,541\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import quantizeml\n",
    "import json\n",
    "from quantizeml.models import quantize, QuantizationParams,dump_config\n",
    "qparams = QuantizationParams(input_weight_bits=8, weight_bits=8, activation_bits=8, output_bits=8,\n",
    "                             per_tensor_activations=True, buffer_bits=24)\n",
    "\n",
    "# Quantize the model\n",
    "quantized_model = quantize(model_keras, qparams=qparams)\n",
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"vgg_utk_face\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " rescaling (QuantizedRescali  (None, 32, 32, 3)        0         \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " conv_0 (QuantizedConv2D)    (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " conv_0/relu (QuantizedReLU)  (None, 30, 30, 32)       64        \n",
      "                                                                 \n",
      " conv_1 (QuantizedConv2D)    (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " conv_1/maxpool (QuantizedMa  (None, 15, 15, 32)       0         \n",
      " xPool2D)                                                        \n",
      "                                                                 \n",
      " conv_1/relu (QuantizedReLU)  (None, 15, 15, 32)       64        \n",
      "                                                                 \n",
      " dropout_3 (QuantizedDropout  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_2 (QuantizedConv2D)    (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " conv_2/relu (QuantizedReLU)  (None, 15, 15, 64)       128       \n",
      "                                                                 \n",
      " conv_3 (QuantizedConv2D)    (None, 15, 15, 64)        36928     \n",
      "                                                                 \n",
      " conv_3/maxpool (QuantizedMa  (None, 8, 8, 64)         0         \n",
      " xPool2D)                                                        \n",
      "                                                                 \n",
      " conv_3/relu (QuantizedReLU)  (None, 8, 8, 64)         128       \n",
      "                                                                 \n",
      " dropout_4 (QuantizedDropout  (None, 8, 8, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_4 (QuantizedConv2D)    (None, 8, 8, 84)          48468     \n",
      "                                                                 \n",
      " conv_4/relu (QuantizedReLU)  (None, 8, 8, 84)         0         \n",
      "                                                                 \n",
      " conv_4/global_avg (Quantize  (None, 84)               2         \n",
      " dGlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_5 (QuantizedDropout  (None, 84)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_1 (QuantizedDense)    (None, 64)                5440      \n",
      "                                                                 \n",
      " dense_1/relu (QuantizedReLU  (None, 64)               2         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_2 (QuantizedDense)    (None, 1)                 65        \n",
      "                                                                 \n",
      " dequantizer (Dequantizer)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119,929\n",
      "Trainable params: 119,541\n",
      "Non-trainable params: 388\n",
      "_________________________________________________________________\n",
      "Keras MAE: 5.8951\n"
     ]
    }
   ],
   "source": [
    "from akida_models import vgg_utk_face_pretrained\n",
    "\n",
    "# Load the pre-trained quantized model\n",
    "model_quantized_keras = vgg_utk_face_pretrained()\n",
    "model_quantized_keras.summary()\n",
    "\n",
    "# Compile the quantized Keras model (required to evaluate the MAE)\n",
    "model_quantized_keras.compile(optimizer='Adam', loss='mae')\n",
    "\n",
    "# Check Keras model performance\n",
    "mae_quant = model_quantized_keras.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Keras MAE: {0:.4f}\".format(mae_quant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model Summary                 \n",
      "______________________________________________\n",
      "Input shape  Output shape  Sequences  Layers\n",
      "==============================================\n",
      "[32, 32, 3]  [1, 1, 1]     1          8     \n",
      "______________________________________________\n",
      "\n",
      "_________________________________________________________\n",
      "Layer (type)               Output shape  Kernel shape  \n",
      "\n",
      "============ SW/conv_0-dequantizer (Software) ===========\n",
      "\n",
      "conv_0 (InputConv2D)       [30, 30, 32]  (3, 3, 3, 32) \n",
      "_________________________________________________________\n",
      "conv_1 (Conv2D)            [15, 15, 32]  (3, 3, 32, 32)\n",
      "_________________________________________________________\n",
      "conv_2 (Conv2D)            [15, 15, 64]  (3, 3, 32, 64)\n",
      "_________________________________________________________\n",
      "conv_3 (Conv2D)            [8, 8, 64]    (3, 3, 64, 64)\n",
      "_________________________________________________________\n",
      "conv_4 (Conv2D)            [1, 1, 84]    (3, 3, 64, 84)\n",
      "_________________________________________________________\n",
      "dense_1 (Dense2D)          [1, 1, 64]    (84, 64)      \n",
      "_________________________________________________________\n",
      "dense_2 (Dense2D)          [1, 1, 1]     (64, 1)       \n",
      "_________________________________________________________\n",
      "dequantizer (Dequantizer)  [1, 1, 1]     N/A           \n",
      "_________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from cnn2snn import convert\n",
    "\n",
    "model_akida = convert(model_quantized_keras)\n",
    "model_akida.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    # Convert frame to RGB if necessary\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Resize frame to the model input size (32, 32, 3)\n",
    "    resized_frame = cv2.resize(rgb_frame, (32, 32))\n",
    "    # Normalize the frame\n",
    "    #normalized_frame = resized_frame / 255.0\n",
    "    #convert to uint8\n",
    "    reduced_frame = resized_frame.astype('uint8')\n",
    "    # Add batch dimension\n",
    "    input_frame = np.expand_dims(reduced_frame, axis=0)\n",
    "    return input_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame for the model\n",
    "    input_frame = preprocess_frame(frame)\n",
    "\n",
    "    # Predict age using the Akida model\n",
    "    age = model_akida.predict(input_frame)\n",
    "\n",
    "    # Display the results on the frame\n",
    "    cv2.putText(frame, f'Age: {int(age)}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Age Estimation', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize deque to store the last 10 age predictions\n",
    "age_buffer = deque(maxlen=10)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame for the model\n",
    "    input_frame = preprocess_frame(frame)\n",
    "\n",
    "    # Predict age using the Akida model\n",
    "    age = model_akida.predict(input_frame)\n",
    "    age_buffer.append(age)\n",
    "\n",
    "    # Calculate the average age\n",
    "    avg_age = np.mean(age_buffer)\n",
    "\n",
    "    # Display the results on the frame\n",
    "    cv2.putText(frame, f'Age: {int(avg_age)}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Age Estimation', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissertation_Environment2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
