{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wanted words and labels:\n",
      " {'six': 23, 'three': 25, 'seven': 21, 'bed': 1, 'eight': 6, 'yes': 31, 'cat': 3, 'on': 18, 'one': 19, 'stop': 24, 'two': 27, 'house': 11, 'five': 7, 'down': 5, 'four': 8, 'go': 9, 'up': 28, 'learn': 12, 'no': 16, 'bird': 2, 'zero': 32, 'nine': 15, 'visual': 29, 'wow': 30, 'sheila': 22, 'marvin': 14, 'off': 17, 'right': 20, 'left': 13, 'happy': 10, 'dog': 4, 'tree': 26, '_silence_': 0}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from akida_models import fetch_file\n",
    "\n",
    "# Fetch pre-processed data for 32 keywords\n",
    "fname = fetch_file(\n",
    "    fname='kws_preprocessed_all_words_except_backward_follow_forward.pkl',\n",
    "    origin=\"https://data.brainchip.com/dataset-mirror/kws/kws_preprocessed_all_words_except_backward_follow_forward.pkl\",\n",
    "    cache_subdir='datasets/kws')\n",
    "with open(fname, 'rb') as f:\n",
    "    [_, _, x_valid, y_valid, _, _, word_to_index, _] = pickle.load(f)\n",
    "\n",
    "# Preprocessed dataset parameters\n",
    "num_classes = len(word_to_index)\n",
    "\n",
    "print(\"Wanted words and labels:\\n\", word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"ds_cnn_kws\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 49, 10, 1)]       0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 49, 10, 1)         0         \n",
      "                                                                 \n",
      " conv_0 (Conv2D)             (None, 25, 5, 64)         1600      \n",
      "                                                                 \n",
      " conv_0/BN (BatchNormalizati  (None, 25, 5, 64)        256       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv_0/relu (ReLU)          (None, 25, 5, 64)         0         \n",
      "                                                                 \n",
      " dw_separable_1 (DepthwiseCo  (None, 25, 5, 64)        576       \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_1 (Conv2D)     (None, 25, 5, 64)         4096      \n",
      "                                                                 \n",
      " pw_separable_1/BN (BatchNor  (None, 25, 5, 64)        256       \n",
      " malization)                                                     \n",
      "                                                                 \n",
      " pw_separable_1/relu (ReLU)  (None, 25, 5, 64)         0         \n",
      "                                                                 \n",
      " dw_separable_2 (DepthwiseCo  (None, 25, 5, 64)        576       \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_2 (Conv2D)     (None, 25, 5, 64)         4096      \n",
      "                                                                 \n",
      " pw_separable_2/BN (BatchNor  (None, 25, 5, 64)        256       \n",
      " malization)                                                     \n",
      "                                                                 \n",
      " pw_separable_2/relu (ReLU)  (None, 25, 5, 64)         0         \n",
      "                                                                 \n",
      " dw_separable_3 (DepthwiseCo  (None, 25, 5, 64)        576       \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_3 (Conv2D)     (None, 25, 5, 64)         4096      \n",
      "                                                                 \n",
      " pw_separable_3/BN (BatchNor  (None, 25, 5, 64)        256       \n",
      " malization)                                                     \n",
      "                                                                 \n",
      " pw_separable_3/relu (ReLU)  (None, 25, 5, 64)         0         \n",
      "                                                                 \n",
      " dw_separable_4 (DepthwiseCo  (None, 25, 5, 64)        576       \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_4 (Conv2D)     (None, 25, 5, 64)         4096      \n",
      "                                                                 \n",
      " pw_separable_4/BN (BatchNor  (None, 25, 5, 64)        256       \n",
      " malization)                                                     \n",
      "                                                                 \n",
      " pw_separable_4/relu (ReLU)  (None, 25, 5, 64)         0         \n",
      "                                                                 \n",
      " pw_separable_4/global_avg (  (None, 64)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 33)                2145      \n",
      "                                                                 \n",
      " act_softmax (Activation)    (None, 33)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,713\n",
      "Trainable params: 23,073\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Retrieve the model file from the BrainChip data server\n",
    "model_file = fetch_file(fname=\"ds_cnn_kws.h5\",\n",
    "                        origin=\"https://data.brainchip.com/models/AkidaV2/ds_cnn/ds_cnn_kws.h5\",\n",
    "                        cache_subdir='models')\n",
    "\n",
    "# Load the native Keras pre-trained model\n",
    "model_keras = load_model(model_file)\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 1s 3ms/step\n",
      "Accuracy: 93.09%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Check Keras Model performance\n",
    "potentials_keras = model_keras.predict(x_valid)\n",
    "preds_keras = np.squeeze(np.argmax(potentials_keras, 1))\n",
    "\n",
    "accuracy = accuracy_score(y_valid, preds_keras)\n",
    "print(\"Accuracy: \" + \"{0:.2f}\".format(100 * accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"ds_cnn_kws\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 49, 10, 1)]       0         \n",
      "                                                                 \n",
      " rescaling (QuantizedRescali  (None, 49, 10, 1)        0         \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " conv_0 (QuantizedConv2D)    (None, 25, 5, 64)         1664      \n",
      "                                                                 \n",
      " conv_0/relu (QuantizedReLU)  (None, 25, 5, 64)        128       \n",
      "                                                                 \n",
      " dw_separable_1 (QuantizedDe  (None, 25, 5, 64)        704       \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_1 (QuantizedCo  (None, 25, 5, 64)        4160      \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_1/relu (Quanti  (None, 25, 5, 64)        128       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_2 (QuantizedDe  (None, 25, 5, 64)        704       \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_2 (QuantizedCo  (None, 25, 5, 64)        4160      \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_2/relu (Quanti  (None, 25, 5, 64)        128       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_3 (QuantizedDe  (None, 25, 5, 64)        704       \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_3 (QuantizedCo  (None, 25, 5, 64)        4160      \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_3/relu (Quanti  (None, 25, 5, 64)        128       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_4 (QuantizedDe  (None, 25, 5, 64)        704       \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_4 (QuantizedCo  (None, 25, 5, 64)        4160      \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_4/relu (Quanti  (None, 25, 5, 64)        0         \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " pw_separable_4/global_avg (  (None, 64)               2         \n",
      " QuantizedGlobalAveragePooli                                     \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_5 (QuantizedDense)    (None, 33)                2145      \n",
      "                                                                 \n",
      " dense_5/dequantizer (Dequan  (None, 33)               0         \n",
      " tizer)                                                          \n",
      "                                                                 \n",
      " act_softmax (Activation)    (None, 33)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,779\n",
      "Trainable params: 22,753\n",
      "Non-trainable params: 1,026\n",
      "_________________________________________________________________\n",
      "308/308 [==============================] - 6s 11ms/step\n",
      "Accuracy: 92.87%\n"
     ]
    }
   ],
   "source": [
    "from quantizeml.models import load_model\n",
    "\n",
    "# Load the pre-trained quantized model\n",
    "model_file = fetch_file(\n",
    "    fname=\"ds_cnn_kws_i8_w8_a8.h5\",\n",
    "    origin=\"https://data.brainchip.com/models/AkidaV2/ds_cnn/ds_cnn_kws_i8_w8_a8.h5\",\n",
    "    cache_subdir='models')\n",
    "model_keras_quantized = load_model(model_file)\n",
    "model_keras_quantized.summary()\n",
    "\n",
    "# Check Model performance\n",
    "potentials_keras_q = model_keras_quantized.predict(x_valid)\n",
    "preds_keras_q = np.squeeze(np.argmax(potentials_keras_q, 1))\n",
    "\n",
    "accuracy_q = accuracy_score(y_valid, preds_keras_q)\n",
    "print(\"Accuracy: \" + \"{0:.2f}\".format(100 * accuracy_q) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ds_cnn_kws\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 49, 10, 1)]       0         \n",
      "                                                                 \n",
      " rescaling (QuantizedRescali  (None, 49, 10, 1)        0         \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " conv_0 (QuantizedConv2D)    (None, 25, 5, 64)         1664      \n",
      "                                                                 \n",
      " conv_0/relu (QuantizedReLU)  (None, 25, 5, 64)        128       \n",
      "                                                                 \n",
      " dw_separable_1 (QuantizedDe  (None, 25, 5, 64)        704       \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_1 (QuantizedCo  (None, 25, 5, 64)        4160      \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_1/relu (Quanti  (None, 25, 5, 64)        128       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_2 (QuantizedDe  (None, 25, 5, 64)        704       \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_2 (QuantizedCo  (None, 25, 5, 64)        4160      \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_2/relu (Quanti  (None, 25, 5, 64)        128       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_3 (QuantizedDe  (None, 25, 5, 64)        704       \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_3 (QuantizedCo  (None, 25, 5, 64)        4160      \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_3/relu (Quanti  (None, 25, 5, 64)        128       \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " dw_separable_4 (QuantizedDe  (None, 25, 5, 64)        704       \n",
      " pthwiseConv2D)                                                  \n",
      "                                                                 \n",
      " pw_separable_4 (QuantizedCo  (None, 25, 5, 64)        4160      \n",
      " nv2D)                                                           \n",
      "                                                                 \n",
      " pw_separable_4/relu (Quanti  (None, 25, 5, 64)        0         \n",
      " zedReLU)                                                        \n",
      "                                                                 \n",
      " pw_separable_4/global_avg (  (None, 64)               2         \n",
      " QuantizedGlobalAveragePooli                                     \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dense_5 (QuantizedDense)    (None, 33)                2145      \n",
      "                                                                 \n",
      " dense_5/dequantizer (Dequan  (None, 33)               0         \n",
      " tizer)                                                          \n",
      "                                                                 \n",
      " act_softmax (Activation)    (None, 33)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,779\n",
      "Trainable params: 22,753\n",
      "Non-trainable params: 1,026\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define QuantizationParams with specific values just for the sake of understanding the JSON\n",
    "# configuration that follows.\n",
    "\n",
    "import quantizeml\n",
    "import json\n",
    "from quantizeml.models import quantize, QuantizationParams,dump_config\n",
    "qparams = QuantizationParams(input_weight_bits=8, weight_bits=4, activation_bits=4,\n",
    "                             per_tensor_activations=True, buffer_bits=24)\n",
    "\n",
    "# Quantize the model\n",
    "quantized_model = quantize(model_keras_quantized, qparams=qparams)\n",
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function NonTrackVariable.set_var at 0x000001A68413B5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function NonTrackVariable.set_var at 0x000001A63CA22C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msaad\\AppData\\Roaming\\Python\\Python38\\site-packages\\cnn2snn\\quantizeml\\blocks.py:160: UserWarning: Conversion stops at layer dense_5 because of a dequantizer. The end of the model is ignored:\n",
      "___________________________________________________\n",
      "Layer (type)\n",
      "===================================================\n",
      "act_softmax (Activation)\n",
      "===================================================\n",
      "\n",
      "  warnings.warn(\"Conversion stops\" + stop_layer_msg + \" because of a dequantizer. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model Summary                 \n",
      "______________________________________________\n",
      "Input shape  Output shape  Sequences  Layers\n",
      "==============================================\n",
      "[49, 10, 1]  [1, 1, 33]    1          11    \n",
      "______________________________________________\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                       Output shape  Kernel shape  \n",
      "\n",
      "============ SW/conv_0-dense_5/dequantizer (Software) ===========\n",
      "\n",
      "conv_0 (InputConv2D)               [25, 5, 64]   (5, 5, 1, 64) \n",
      "_________________________________________________________________\n",
      "dw_separable_1 (DepthwiseConv2D)   [25, 5, 64]   (3, 3, 64, 1) \n",
      "_________________________________________________________________\n",
      "pw_separable_1 (Conv2D)            [25, 5, 64]   (1, 1, 64, 64)\n",
      "_________________________________________________________________\n",
      "dw_separable_2 (DepthwiseConv2D)   [25, 5, 64]   (3, 3, 64, 1) \n",
      "_________________________________________________________________\n",
      "pw_separable_2 (Conv2D)            [25, 5, 64]   (1, 1, 64, 64)\n",
      "_________________________________________________________________\n",
      "dw_separable_3 (DepthwiseConv2D)   [25, 5, 64]   (3, 3, 64, 1) \n",
      "_________________________________________________________________\n",
      "pw_separable_3 (Conv2D)            [25, 5, 64]   (1, 1, 64, 64)\n",
      "_________________________________________________________________\n",
      "dw_separable_4 (DepthwiseConv2D)   [25, 5, 64]   (3, 3, 64, 1) \n",
      "_________________________________________________________________\n",
      "pw_separable_4 (Conv2D)            [1, 1, 64]    (1, 1, 64, 64)\n",
      "_________________________________________________________________\n",
      "dense_5 (Dense2D)                  [1, 1, 33]    (64, 33)      \n",
      "_________________________________________________________________\n",
      "dense_5/dequantizer (Dequantizer)  [1, 1, 33]    N/A           \n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from cnn2snn import convert\n",
    "\n",
    "# Convert the model\n",
    "model_akida = convert(model_keras_quantized)\n",
    "model_akida.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "\n",
    "    def start(self):\n",
    "        self.start_time = time.perf_counter()\n",
    "\n",
    "    def stop(self):\n",
    "        self.end_time = time.perf_counter()\n",
    "        return self.end_time - self.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction took 2.4964 seconds\n",
      "Accuracy: 92.87%\n"
     ]
    }
   ],
   "source": [
    "# Check Akida model performance\n",
    "timer = Timer()\n",
    "timer.start()\n",
    "preds_akida = model_akida.predict_classes(x_valid, num_classes=num_classes)\n",
    "prediction_time = timer.stop()\n",
    "print(f\"Prediction took {prediction_time:.4f} seconds\")\n",
    "\n",
    "accuracy = accuracy_score(y_valid, preds_akida)\n",
    "print(\"Accuracy: \" + \"{0:.2f}\".format(100 * accuracy) + \"%\")\n",
    "\n",
    "# For non-regression purposes\n",
    "#assert accuracy > 0.9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissertation_Environment2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
